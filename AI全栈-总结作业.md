# **一、为什么参加这个训练营**
- 作为服务后端和系统集成背景的非AI原生开发，面对AI技术，既兴奋又焦虑。兴奋在于AI带来的无限可能，焦虑在于把握不清技术形势，在五花八门的技术或产品词汇中迷失方向。
- 参加训练营的初衷就是构建AI全栈的技术视角，提升AI技术理解力，实现向AI应用开发的角色转向。
# **二、课程全景回顾**
- 训练营课程由核心理论、前沿技术、实战项目、行业赋能几个板块组成，并具体划分为理论前置篇、Deepseek篇、Dify篇、MCP篇、FastGPT篇、企业篇、模型篇和训练篇，此处结合自己认知，对课程内容进行适当重排和简要回顾，便于后续在此基础上查缺补漏，夯实基础，扩大图谱。
## **1.理论：AI通识基础**
- **传统机器学习**：监督学习、非监督学习、半监督学习三大范式，大量依赖人工进行特征提取。
- **深度学习**：CNN（AlexNet、ResNet等）、RNN/LSTM/GRU等，一般由多层次网络自动学习特征。
- **大语言模型**: Transformer
    - 核心概念：激活函数、前向与反向传播
    - 核心机制：注意力模型、自注意力机制、多头注意力机制、位置编码、MOE
    - 典型特征：参数规模巨大、海量训练数据、涌现能力、泛化与通用性
    - 训练范式：预训练+微调/指令跟随+后训练（RL）
    - 技术演进：知识驱动->推理驱动
    - 前沿趋势：
        - a.多模态融合
        - b.Agent与具身智能：让大模型与环境交互，执行复杂任务
        - c.模型压缩与部署：大模型能力普惠化
- **特别：DeepSeek技术分解**
## **2.实践：AI各阶技术**
### 2.1 （一阶）提示工程->**上下文工程**
- 好的提示：清晰的目标+充分的信息+明确的指引
- 核心原则：清晰明确、提供上下文、指定角色、明确任务、指定输出
- 进阶技巧：few shots、COT提示、控制输出长度与格式、**迭代**
### 2.2 （二阶）AI智能体
#### 核心组件：向量数据库
- 核心任务：相似度搜索，算法（余弦相似度、欧式距离、点积）、ANN搜索
- 典型架构：数据接入层、存储层、**index索引层**、查询处理层、管理与监控
#### **技术选型**：
- （1）普通大模型 vs 推理大模型
    - 普通大模型：文本分类与摘要、对话客服机器人、文本生成、语言翻译、信息抽取、语义搜索/FAQ匹配
    - 推理大模型：数学题解/逻辑推理、代码理解与生成、复杂问答系统、结构化文档生成、企业决策支持、多Agent协同任务
    - 具体考量
        * 判断是否推理：多个步骤解答？分析多个上下文？明显因果逻辑链？精确计算/代码推导？
- （2）向量数据库选型：开源自建 vs 云服务托管
    - 开源自建：Milvus、Weaviate（图结构）、Qdrant、Chroma（python优先）、Faiss（很多向量库底层）
    - 云服务托管：Pinecone、ZillizCloud(Milvus商用)、云厂商服务
    - 具体考量因素：
        * 性能：查询延迟、吞吐量、索引构建时间
        * 可扩展性：数据量和查询量增长适应性、水平扩展？
        * 准确性：ANN召回？速度vs精度
        * 易用性与生态：API友好、文档完善、社区、成熟SDK
        * 功能特性：哪些ANN索引算法？支持元数据过滤？支持混合搜索（向量+关键词）？
    - 选型建议：快速原型/学习、生产环境/大规模、具体需求（性能、功能、成本、运维能力侧重）
#### **核心技术**
- **RAG技术**
    - 技术要点1：数据预处理与切块（切多大、怎么切、**元数据**）
    - 技术要点2：嵌入模型选择（查询/文档一致性、领域适应性）
    - 技术要点3：检索策略（TopK、相似度阈值、混合检索、rerank）
    - 技术要点4：上下文构建与提示工程（指令清晰、处理超长/冲突）
    - 技术要点5：生成模型选择（指令遵循好、上下文窗口大）
    - 技术要点6：**评估与迭代**
        - 检索质量：召回率、精确率、MRR
        - 生成质量：答案相关性、准确性、流畅性、是否有害
        - 端到端评估：具体业务场景
        - 持续监控、分析bad case、优化
- **Agent技术**：
    - Agent技术栈拆解
        - 核心能力层：自主**规划**+使用**工具**+根据反馈**行动**+记忆
        - 开发框架层：LangChain、LlamaIndex等
        - 模型服务层：开源（deepseek等）+闭源（openai等）
    - Agent架构：
        - 1.核心逻辑控制器：驱动整个Agent运行（如ReAct循环）
        - 2.规划模块：LLM分解任务、制定计划
        - 3.工具集：定义工具，提供接口
        - 4.记忆模块：短期（对话）+长期（知识库）
        - 5.行动执行器：执行LLM决定的动作
    - Agent开发流程：
        - 1.工具开发与集成
        - 2.**提示工程**：包含角色、目标、可用工具描述、输出格式、COT模板
        - 3.记忆机制：选型如列表or向量数据库
        - 4.测试、评估、迭代：场景测试
- **私有化部署**
    - 决策框架：数据与合规、模型定制化、性能与集成、成本与规模（TCO测算）、技术与运维
    - 私有化技术栈
        - 应用接口层：API网关（Nginx、Kong）
        - 监控与日志层：Prometheus+Grafana、ELK/Loki
        - 容器编排层：K8s、docker compose
        - **推理服务层**:核心引擎：Ollama、vLLM、Triton、TGI、llama.cpp
        - 容器化层：docker
        - 模型与数据层：deepseek、Qwen等
        - 基础设施层：GPU服务器
    - 显存评估：总显存 > (模型大小 * 每个参数字节数 * 精度)
- **低代码平台：Dify**
- **低代码平台：FastGPT**
### 2.3 （三阶）大模型微调
- 待补充
### 2.4 （四阶）预训练技术
- 本课程不涉及
## **3.应用：企业级落地**
- 待补充
# **三、实战项目复盘**
## 1.RAG实战：民法典
- 应用场景：将民法典（节选）文档构建为知识库，构建为RAG，并FAQ测试效果。
- 选型：Milvus、jupterlab、Deepseek
- 关键尝试：切块后同时维护法条所属编、章、条号等元数据信息。
## 2.Agent实战：小红书爆款文案
- 需求/痛点：高频发布、创意瓶颈、趋势、平台特性（风格、特征）
- 核心工作流：
    - 用户指令接收：产品信息、主题、风格等
    - 信息收集（Web Search/DB Query）：搜索行业趋势、热门话题、竞品分析、产品卖点等
    - 内容构思与初稿生成（LLM）：结合信息，撰写标题、正文、标签、表情等
    - 风格与格式优化（LLM）：根据小红书平台特点/风格，进行润色、结构调整
    - 最终输出：文案呈现
- AI技术应用
    - Prompt设计：角色设定、目标、行为准则（Thought-Action-Observation）
    - ReAct模式：通过TAO，使Agent多步骤推理、工具调用
    - Tools：search_web/query_databse/generate_emoji
    - Few-shot Examples
    - 输出格式与约束
- **迭代/优化思考**
    - 策略评估：客观指标评估（数据）+主观内部评估（人工）
    - 策略优化：prompt优化、新工具扩充、RAG引入
## 3.企业微信智能客服...
## 4.代码生成助手...
## 5.企业级RAG系统...

# 四、个人成长与认知迭代
- 持续总结触动自己的点：
    - AI应用/产品的成功，除了AI技术本身加持，更离不开系统设计和各种工程化技术的紧密协同。
    - 跑通产品demo在技术上是相对容易和清晰的，但数据质量/业务认知才是决定产品上限的关键。
    - 
# 五、能力图谱更新
- 以AI四阶技术栈为底座的AI技术理解里，初步具备AI应用架构思维
- 快速MVP原型能力：低代码、手搓
- 企业级AI应用迭代演进思维

# 六、致谢
- 本课程整体设计有理论有实操，各章节内容详略有度，配合老彭层层递进的清晰讲解，值得反复学习，确实是值得安利的好课。
- 此外，极客时间打造课程的深厚班底，以及各位助教、班班老师对课程的全心投入、对学员问题的专业及时响应，更是极大提升了此次训练营的服务体验。
- 综上，对老彭、助教、班班老师送上真挚感谢，期待后续继续推出优质新课。